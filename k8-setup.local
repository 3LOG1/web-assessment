#Steps for creating k8s setup 

cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# sysctl params required by setup, params persist across reboots
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# Apply sysctl params without reboot
sudo sysctl --system

#Disable Swap

sudo swapoff -a
(crontab -l 2>/dev/null; echo "@reboot /sbin/swapoff -a") | crontab - || true


# Kuernetes Variable Declaration

KUBERNETES_VERSION=v1.32
CRIO_VERSION=v1.32

# Apply sysctl params without reboot
sudo sysctl --system

sudo apt-get update -y
sudo apt-get install -y apt-transport-https ca-certificates curl gpg

## Install CRIO Runtime

sudo apt-get update -y
apt-get install -y software-properties-common curl apt-transport-https ca-certificates


curl -fsSL https://pkgs.k8s.io/addons:/cri-o:/stable:/$CRIO_VERSION/deb/Release.key |
    gpg --dearmor -o /etc/apt/keyrings/cri-o-apt-keyring.gpg

echo "deb [signed-by=/etc/apt/keyrings/cri-o-apt-keyring.gpg] https://pkgs.k8s.io/addons:/cri-o:/stable:/$CRIO_VERSION/deb/ /" |
    tee /etc/apt/sources.list.d/cri-o.list


sudo apt-get update -y
sudo apt-get install -y cri-o

sudo systemctl daemon-reload
sudo systemctl enable crio --now
sudo systemctl start crio.service

echo "CRI runtime installed susccessfully"




KUBERNETES_VERSION=v1.32

curl -fsSL https://pkgs.k8s.io/core:/stable:/$KUBERNETES_VERSION/deb/Release.key |
    gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/$KUBERNETES_VERSION/deb/ /" |
    tee /etc/apt/sources.list.d/kubernetes.list


sudo apt-get update -y


KUBERNETES_INSTALL_VERSION=1.32.5-1.1

sudo apt-get install -y kubelet="$KUBERNETES_INSTALL_VERSION" kubectl="$KUBERNETES_INSTALL_VERSION" kubeadm="$KUBERNETES_INSTALL_VERSION"

sudo apt-get install -y kubelet kubeadm kubectl

sudo apt-mark hold kubelet kubeadm kubectl
#=================================
cat > /etc/default/kubelet << EOF

KUBELET_EXTRA_ARGS=--node-ip=<<Add local IP>>

EOF
#===========================


#create the Kubeadm Configfile.
apiVersion: kubeadm.k8s.io/v1beta4
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: "192.168.1.74"
  bindPort: 6443
nodeRegistration:
  name: "controlplane"
  criSocket: unix:///var/run/crio/crio.sock
---
apiVersion: kubeadm.k8s.io/v1beta4
kind: ClusterConfiguration
kubernetesVersion: "v1.32.0"
controlPlaneEndpoint: "192.168.1.74:6443"
apiServer:
  extraArgs:
    - name: "enable-admission-plugins"
      value: "NodeRestriction"
    - name: "audit-log-path"
      value: "/var/log/kubernetes/audit.log"
controllerManager:
  extraArgs:
    - name: "node-cidr-mask-size"
      value: "24"
scheduler:
  extraArgs:
    - name: "leader-elect"
      value: "true"
networking:
  podSubnet: "10.244.0.0/16"
  serviceSubnet: "10.96.0.0/12"
  dnsDomain: "cluster.local"

---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
cgroupDriver: "systemd"
syncFrequency: "1m"

---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
mode: "ipvs"
conntrack:
  maxPerCore: 32768
  min: 131072
  tcpCloseWaitTimeout: "1h"
  tcpEstablishedTimeout: "24h"
#=====================================


#Initialize kubeadm

kubeadm init --config=kubeadm.config

#after succefull initialization check the status

curl -vk https://<<local-ip>>:6443/healthz

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config


#List pods --All namespace
kubectl get pods -A

#Check Cluster info
kubectl cluster-info

#Install CNI -for pod networking

kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.29.1/manifests/tigera-operator.yaml

curl https://raw.githubusercontent.com/projectcalico/calico/v3.29.1/manifests/custom-resources.yaml -O

#Add CIDR range in custom-resources.yaml
apiVersion: operator.tigera.io/v1
kind: Installation
metadata:
  name: default
spec:
  # Configures Calico networking.
  calicoNetwork:
    ipPools:
    - name: default-ipv4-ippool
      blockSize: 26
#      cidr: 192.168.0.0/16
      cidr: 10.244.0.0/16
      encapsulation: VXLANCrossSubnet
      natOutgoing: Enabled
      nodeSelector: all()
#=====================================Deploy========
kubectl apply -f custom-resources.yaml


#Sample OUT

kubectl get pods -A 
NAMESPACE         NAME                                        READY   STATUS    RESTARTS       AGE
calico-system     calico-kube-controllers-8445cc7766-rhkmv    1/1     Running   0              2d
calico-system     calico-node-dvqpk                           1/1     Running   1 (1d ago)    2d
calico-system     calico-node-zlqlw                           1/1     Running   0              2d
calico-system     calico-typha-67fc6cfdb4-c5m8p               1/1     Running   0              2d
calico-system     csi-node-driver-87tvd                       2/2     Running   0              2d
calico-system     csi-node-driver-gzfpw                       2/2     Running   0              2d
demo              web-7f57c7cdf9-7k9wb                        1/1     Running   0              178m
demo              web-7f57c7cdf9-ghzt8                        1/1     Running   0              178m
demo              web-7f57c7cdf9-wrvhp                        1/1     Running   0              178m
ingress-nginx     ingress-nginx-controller-7d8cffd99c-nqzx6   1/1     Running   0              3h16m
kube-system       coredns-668d6bf9bc-2qqc6                    1/1     Running   0              2d
kube-system       coredns-668d6bf9bc-n77rq                    1/1     Running   0              2d
kube-system       etcd-controlplane                           1/1     Running   3              2d
kube-system       kube-apiserver-controlplane                 1/1     Running   0              2d
kube-system       kube-controller-manager-controlplane        1/1     Running   10 (1d ago)   2d
kube-system       kube-proxy-5tdph                            1/1     Running   0              2d
kube-system       kube-proxy-8zknr                            1/1     Running   0              2d
kube-system       kube-scheduler-controlplane                 1/1     Running   9 (1d ago)    2d
tigera-operator   tigera-operator-7b9dcd4cd7-97fkn            1/1     Running   11 (1d ago)   2d
#============================================================================================
